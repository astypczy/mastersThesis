# .github/workflows/ci-backend.yml
name: CI Â· Backend (Ubuntu + Postgres service)

on:
  push:
    branches: [main]
    paths:
      - 'backend/**'
  pull_request:
    branches: [main]
    paths:
      - 'backend/**'

jobs:
  build-migrate-rollback:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_DB: mastersThesis
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - "5432:5432"
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    env:
      DB_URL: jdbc:postgresql://localhost:5432/mastersThesis
      DB_USER: postgres
      DB_PASS: postgres
      PGPASSWORD: postgres

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          distribution: temurin
          java-version: '17'

      - name: Export JAVA_HOME
        run: echo "JAVA_HOME=$JAVA_HOME" >> $GITHUB_ENV

      - name: Build backend (skip tests)
        working-directory: backend
        run: mvn clean package -DskipTests

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          pip install psycopg2 faker

      - name: Run Python DB initializer
        run: python sql/addData.py

      - name: Download & unpack Flyway CLI
        run: |
          FLYWAY_VERSION=10.20.1
          curl -L "https://repo1.maven.org/maven2/org/flywaydb/flyway-commandline/${FLYWAY_VERSION}/flyway-commandline-${FLYWAY_VERSION}-linux-x64.tar.gz" \
            | tar xz -C $HOME
          chmod +x $HOME/flyway-${FLYWAY_VERSION}/flyway
          echo "$HOME/flyway-${FLYWAY_VERSION}" >> $GITHUB_PATH

      - name: Prepare metrics directories & CSVs
        run: |
          mkdir -p metricsFlyway metricsLiquibase
          echo "tool,scenario,ctx,migrationTimeNs,rollbackTimeNs,exitCode,scriptLines,cpuUsage,memoryUsage,successRate" > metricsFlyway/flyway.csv
          echo "tool,scenario,ctx,migrationTimeNs,rollbackTimeNs,exitCode,scriptLines,cpuUsage,memoryUsage,successRate" > metricsLiquibase/liquibase.csv

      - name: Bootstrap Flyway schema history
        run: |
          $HOME/flyway-10.20.1/flyway \
            -url="$DB_URL" \
            -user="$DB_USER" \
            -password="$DB_PASS" \
            -baselineOnMigrate=true \
            info

      - name: Run Flyway migrations & rollbacks
        shell: bash
        run: |
          for iter in {1..100}; do
            # for ctx in {2..14}; do
            #   START=$(date +%s%N)
            #   $HOME/flyway-10.20.1/flyway \
            #     -url="$DB_URL" \
            #     -user="$DB_USER" \
            #     -password="$DB_PASS" \
            #     -baselineOnMigrate=true \
            #     -locations=filesystem:backend/src/main/resources/db/migration \
            #     migrate -target="${ctx}"
            #   EXIT=$?
            #   DURATION=$(( $(date +%s%N) - START ))
            #   LINES=$(wc -l backend/src/main/resources/db/migration/V${ctx}__*.sql | awk '{print $1}')
            #   echo "Flyway,Scen1,${ctx},${DURATION},0,${EXIT},${LINES},0,0,100.0" \
            #     >> metricsFlyway/flyway.csv
            # done

            for ctx in {15..24}; do
              START=$(date +%s%N)
              $HOME/flyway-10.20.1/flyway \
                -url="$DB_URL" \
                -user="$DB_USER" \
                -password="$DB_PASS" \
                -baselineOnMigrate=true \
                -locations=filesystem:backend/src/main/resources/db/migration \
                migrate -target="${ctx}"
              EXIT=$?
              DURATION=$(( $(date +%s%N) - START ))
              LINES=$(wc -l backend/src/main/resources/db/migration/V${ctx}__*.sql | awk '{print $1}')
              echo "Flyway,Scen2,${ctx},${DURATION},0,${EXIT},${LINES},0,0,100.0" \
                >> metricsFlyway/flyway.csv
            done

            for ctx in {24..15}; do
              UNDO_SQL="backend/src/main/resources/db/migration/U${ctx}__*.sql"
              START=$(date +%s%N)
              psql -h localhost -U postgres -d mastersThesis -f $UNDO_SQL
              psql -h localhost -U postgres -d mastersThesis \
                -c "DELETE FROM flyway_schema_history WHERE version = '${ctx}';"
              DURATION=$(( $(date +%s%N) - START ))
              LINES=$(wc -l $UNDO_SQL | awk '{print $1}')
              echo "Flyway-R,Scen2,${ctx},0,${DURATION},0,${LINES},0,0,100.0" \
                >> metricsFlyway/flyway.csv
            done

            # for ctx in {14..2}; do
            #   UNDO_SQL="backend/src/main/resources/db/migration/U${ctx}__*.sql"
            #   START=$(date +%s%N)
            #   psql -h localhost -U postgres -d mastersThesis -f $UNDO_SQL
            #   psql -h localhost -U postgres -d mastersThesis \
            #     -c "DELETE FROM flyway_schema_history WHERE version = '${ctx}';"
            #   DURATION=$(( $(date +%s%N) - START ))
            #   LINES=$(wc -l $UNDO_SQL | awk '{print $1}')
            #   echo "Flyway-R,Scen1,${ctx},0,${DURATION},0,${LINES},0,0,100.0" \
            #     >> metricsFlyway/flyway.csv
            # done
          done
        env:
          PGHOST: localhost

      - name: Install Liquibase via APT
        run: |
          wget -O- https://repo.liquibase.com/liquibase.asc \
            | gpg --dearmor > liquibase-keyring.gpg \
            && sudo mv liquibase-keyring.gpg /usr/share/keyrings/ \
            && echo 'deb [arch=amd64 signed-by=/usr/share/keyrings/liquibase-keyring.gpg] https://repo.liquibase.com stable main' \
               | sudo tee /etc/apt/sources.list.d/liquibase.list > /dev/null
          sudo apt-get update
          sudo apt-get install -y liquibase
      
      - name: Run Python DB initializer
        run: python sql/addData.py

      - name: Run Liquibase migrations & rollbacks
        shell: bash
        run: |
          set +e
          for iter in {1..100}; do
            # for ctx in {1..13}; do
            #   START=$(date +%s%N)
            #   liquibase \
            #     --changeLogFile=backend/src/main/resources/db/changelog/db.changelog-master.xml \
            #     --url="$DB_URL" --username="$DB_USER" --password="$DB_PASS" \
            #     update --contexts="${ctx}" \
            #     || true
            #   DURATION=$(( $(date +%s%N) - START ))
            #   LINES=$(grep -c "changeSet id=\"${ctx}\"" backend/src/main/resources/db/changelog/db.changelog-master.xml)
            #   echo "Liquibase,Scen1,${ctx},${DURATION},0,0,${LINES},0,0,100.0" \
            #     >> metricsLiquibase/liquibase.csv
            # done

            for ctx in {14..23}; do
              START=$(date +%s%N)
              liquibase \
                --changeLogFile=backend/src/main/resources/db/changelog/db.changelog-master.xml \
                --url="$DB_URL" --username="$DB_USER" --password="$DB_PASS" \
                update --contexts="${ctx}" \
                || true
              DURATION=$(( $(date +%s%N) - START ))
              LINES=$(grep -c "changeSet id=\"${ctx}\"" backend/src/main/resources/db/changelog/db.changelog-master.xml)
              echo "Liquibase,Scen2,${ctx},${DURATION},0,0,${LINES},0,0,100.0" \
                >> metricsLiquibase/liquibase.csv
            done

            for ctx in {23..14}; do
              START=$(date +%s%N)
              liquibase \
                --changeLogFile=backend/src/main/resources/db/changelog/db.changelog-master.xml \
                --url="$DB_URL" --username="$DB_USER" --password="$DB_PASS" \
                rollbackCount 1 --contexts="${ctx}" \
                || true
              DURATION=$(( $(date +%s%N) - START ))
              LINES=$(grep -c "changeSet id=\"${ctx}\"" backend/src/main/resources/db/changelog/db.changelog-master.xml)
              echo "Liquibase-R,Scen2,${ctx},0,${DURATION},0,${LINES},0,0,100.0" \
                >> metricsLiquibase/liquibase.csv
            done

            # for ctx in {13..1}; do
            #   START=$(date +%s%N)
            #   liquibase \
            #     --changeLogFile=backend/src/main/resources/db/changelog/db.changelog-master.xml \
            #     --url="$DB_URL" --username="$DB_USER" --password="$DB_PASS" \
            #     rollbackCount 1 --contexts="${ctx}" \
            #     || true
            #   DURATION=$(( $(date +%s%N) - START ))
            #   LINES=$(grep -c "changeSet id=\"${ctx}\"" backend/src/main/resources/db/changelog/db.changelog-master.xml)
            #   echo "Liquibase-R,Scen1,${ctx},0,${DURATION},0,${LINES},0,0,100.0" \
            #     >> metricsLiquibase/liquibase.csv
            # done
          done
        env:
          JAVA_HOME: ${{ env.JAVA_HOME }}

      - name: Upload Flyway metrics
        uses: actions/upload-artifact@v4
        with:
          name: flyway-metrics
          path: metricsFlyway/flyway.csv

      - name: Upload Liquibase metrics
        uses: actions/upload-artifact@v4
        with:
          name: liquibase-metrics
          path: metricsLiquibase/liquibase.csv